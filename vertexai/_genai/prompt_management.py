# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Code generated by the Google Gen AI SDK generator DO NOT EDIT.

import json
import logging
import time
from typing import Any, Optional, Union
from urllib.parse import urlencode

from google.genai import _api_module
from google.genai import _common
from google.genai import types as genai_types
from google.genai._common import get_value_by_path as getv
from google.genai._common import set_value_by_path as setv

from . import _prompt_management_utils
from . import types


logger = logging.getLogger("vertexai_genai.promptmanagement")


def _SchemaTextPromptDatasetMetadata_to_vertex(
    from_object: Union[dict[str, Any], object],
    parent_object: Optional[dict[str, Any]] = None,
) -> dict[str, Any]:
    to_object: dict[str, Any] = {}
    if getv(from_object, ["candidate_count"]) is not None:
        setv(to_object, ["candidateCount"], getv(from_object, ["candidate_count"]))

    if getv(from_object, ["gcs_uri"]) is not None:
        setv(to_object, ["gcsUri"], getv(from_object, ["gcs_uri"]))

    if getv(from_object, ["grounding_config"]) is not None:
        setv(to_object, ["groundingConfig"], getv(from_object, ["grounding_config"]))

    if getv(from_object, ["has_prompt_variable"]) is not None:
        setv(
            to_object, ["hasPromptVariable"], getv(from_object, ["has_prompt_variable"])
        )

    if getv(from_object, ["logprobs"]) is not None:
        setv(to_object, ["logprobs"], getv(from_object, ["logprobs"]))

    if getv(from_object, ["max_output_tokens"]) is not None:
        setv(to_object, ["maxOutputTokens"], getv(from_object, ["max_output_tokens"]))

    if getv(from_object, ["note"]) is not None:
        setv(to_object, ["note"], getv(from_object, ["note"]))

    if getv(from_object, ["prompt_api_schema"]) is not None:
        setv(to_object, ["promptApiSchema"], getv(from_object, ["prompt_api_schema"]))

    if getv(from_object, ["prompt_type"]) is not None:
        setv(to_object, ["promptType"], getv(from_object, ["prompt_type"]))

    if getv(from_object, ["seed_enabled"]) is not None:
        setv(to_object, ["seedEnabled"], getv(from_object, ["seed_enabled"]))

    if getv(from_object, ["seed_value"]) is not None:
        setv(to_object, ["seedValue"], getv(from_object, ["seed_value"]))

    if getv(from_object, ["stop_sequences"]) is not None:
        setv(to_object, ["stopSequences"], getv(from_object, ["stop_sequences"]))

    if getv(from_object, ["system_instruction"]) is not None:
        setv(
            to_object, ["systemInstruction"], getv(from_object, ["system_instruction"])
        )

    if getv(from_object, ["system_instruction_gcs_uri"]) is not None:
        setv(
            to_object,
            ["systemInstructionGcsUri"],
            getv(from_object, ["system_instruction_gcs_uri"]),
        )

    if getv(from_object, ["temperature"]) is not None:
        setv(to_object, ["temperature"], getv(from_object, ["temperature"]))

    if getv(from_object, ["text"]) is not None:
        setv(to_object, ["text"], getv(from_object, ["text"]))

    if getv(from_object, ["top_k"]) is not None:
        setv(to_object, ["topK"], getv(from_object, ["top_k"]))

    if getv(from_object, ["top_p"]) is not None:
        setv(to_object, ["topP"], getv(from_object, ["top_p"]))

    return to_object


def _CreateDatasetParameters_to_vertex(
    from_object: Union[dict[str, Any], object],
    parent_object: Optional[dict[str, Any]] = None,
) -> dict[str, Any]:
    to_object: dict[str, Any] = {}
    if getv(from_object, ["config"]) is not None:
        setv(to_object, ["config"], getv(from_object, ["config"]))

    if getv(from_object, ["name"]) is not None:
        setv(to_object, ["name"], getv(from_object, ["name"]))

    if getv(from_object, ["display_name"]) is not None:
        setv(to_object, ["displayName"], getv(from_object, ["display_name"]))

    if getv(from_object, ["metadata_schema_uri"]) is not None:
        setv(
            to_object, ["metadataSchemaUri"], getv(from_object, ["metadata_schema_uri"])
        )

    if getv(from_object, ["metadata"]) is not None:
        setv(
            to_object,
            ["metadata"],
            _SchemaTextPromptDatasetMetadata_to_vertex(
                getv(from_object, ["metadata"]), to_object
            ),
        )

    if getv(from_object, ["description"]) is not None:
        setv(to_object, ["description"], getv(from_object, ["description"]))

    if getv(from_object, ["encryption_spec"]) is not None:
        setv(to_object, ["encryptionSpec"], getv(from_object, ["encryption_spec"]))

    if getv(from_object, ["model_reference"]) is not None:
        setv(to_object, ["modelReference"], getv(from_object, ["model_reference"]))

    return to_object


def _DatasetVersion_to_vertex(
    from_object: Union[dict[str, Any], object],
    parent_object: Optional[dict[str, Any]] = None,
) -> dict[str, Any]:
    to_object: dict[str, Any] = {}
    if getv(from_object, ["metadata"]) is not None:
        setv(
            to_object,
            ["metadata"],
            _SchemaTextPromptDatasetMetadata_to_vertex(
                getv(from_object, ["metadata"]), to_object
            ),
        )

    if getv(from_object, ["big_query_dataset_name"]) is not None:
        setv(
            to_object,
            ["bigQueryDatasetName"],
            getv(from_object, ["big_query_dataset_name"]),
        )

    if getv(from_object, ["create_time"]) is not None:
        setv(to_object, ["createTime"], getv(from_object, ["create_time"]))

    if getv(from_object, ["display_name"]) is not None:
        setv(to_object, ["displayName"], getv(from_object, ["display_name"]))

    if getv(from_object, ["etag"]) is not None:
        setv(to_object, ["etag"], getv(from_object, ["etag"]))

    if getv(from_object, ["model_reference"]) is not None:
        setv(to_object, ["modelReference"], getv(from_object, ["model_reference"]))

    if getv(from_object, ["name"]) is not None:
        setv(to_object, ["name"], getv(from_object, ["name"]))

    if getv(from_object, ["satisfies_pzi"]) is not None:
        setv(to_object, ["satisfiesPzi"], getv(from_object, ["satisfies_pzi"]))

    if getv(from_object, ["satisfies_pzs"]) is not None:
        setv(to_object, ["satisfiesPzs"], getv(from_object, ["satisfies_pzs"]))

    if getv(from_object, ["update_time"]) is not None:
        setv(to_object, ["updateTime"], getv(from_object, ["update_time"]))

    return to_object


def _CreateDatasetVersionParameters_to_vertex(
    from_object: Union[dict[str, Any], object],
    parent_object: Optional[dict[str, Any]] = None,
) -> dict[str, Any]:
    to_object: dict[str, Any] = {}
    if getv(from_object, ["config"]) is not None:
        setv(to_object, ["config"], getv(from_object, ["config"]))

    if getv(from_object, ["dataset_name"]) is not None:
        setv(to_object, ["_url", "name"], getv(from_object, ["dataset_name"]))

    if getv(from_object, ["dataset_version"]) is not None:
        setv(
            to_object,
            ["datasetVersion"],
            _DatasetVersion_to_vertex(
                getv(from_object, ["dataset_version"]), to_object
            ),
        )

    if getv(from_object, ["parent"]) is not None:
        setv(to_object, ["parent"], getv(from_object, ["parent"]))

    if getv(from_object, ["display_name"]) is not None:
        setv(to_object, ["displayName"], getv(from_object, ["display_name"]))

    return to_object


def _GetDatasetParameters_to_vertex(
    from_object: Union[dict[str, Any], object],
    parent_object: Optional[dict[str, Any]] = None,
) -> dict[str, Any]:
    to_object: dict[str, Any] = {}
    if getv(from_object, ["config"]) is not None:
        setv(to_object, ["config"], getv(from_object, ["config"]))

    if getv(from_object, ["name"]) is not None:
        setv(to_object, ["_url", "name"], getv(from_object, ["name"]))

    return to_object


def _GetDatasetVersionParameters_to_vertex(
    from_object: Union[dict[str, Any], object],
    parent_object: Optional[dict[str, Any]] = None,
) -> dict[str, Any]:
    to_object: dict[str, Any] = {}
    if getv(from_object, ["config"]) is not None:
        setv(to_object, ["config"], getv(from_object, ["config"]))

    if getv(from_object, ["dataset_id"]) is not None:
        setv(to_object, ["_url", "dataset_id"], getv(from_object, ["dataset_id"]))

    if getv(from_object, ["dataset_version_id"]) is not None:
        setv(
            to_object,
            ["_url", "dataset_version_id"],
            getv(from_object, ["dataset_version_id"]),
        )

    return to_object


def _GetDatasetOperationParameters_to_vertex(
    from_object: Union[dict[str, Any], object],
    parent_object: Optional[dict[str, Any]] = None,
) -> dict[str, Any]:
    to_object: dict[str, Any] = {}
    if getv(from_object, ["config"]) is not None:
        setv(to_object, ["config"], getv(from_object, ["config"]))

    if getv(from_object, ["dataset_id"]) is not None:
        setv(to_object, ["_url", "dataset_id"], getv(from_object, ["dataset_id"]))

    if getv(from_object, ["operation_id"]) is not None:
        setv(to_object, ["_url", "operation_id"], getv(from_object, ["operation_id"]))

    return to_object


def _DatasetOperation_from_vertex(
    from_object: Union[dict[str, Any], object],
    parent_object: Optional[dict[str, Any]] = None,
) -> dict[str, Any]:
    to_object: dict[str, Any] = {}
    if getv(from_object, ["name"]) is not None:
        setv(to_object, ["name"], getv(from_object, ["name"]))

    if getv(from_object, ["metadata"]) is not None:
        setv(to_object, ["metadata"], getv(from_object, ["metadata"]))

    if getv(from_object, ["done"]) is not None:
        setv(to_object, ["done"], getv(from_object, ["done"]))

    if getv(from_object, ["error"]) is not None:
        setv(to_object, ["error"], getv(from_object, ["error"]))

    if getv(from_object, ["response"]) is not None:
        setv(to_object, ["response"], getv(from_object, ["response"]))

    return to_object


def _SchemaTextPromptDatasetMetadata_from_vertex(
    from_object: Union[dict[str, Any], object],
    parent_object: Optional[dict[str, Any]] = None,
) -> dict[str, Any]:
    to_object: dict[str, Any] = {}
    if getv(from_object, ["candidateCount"]) is not None:
        setv(to_object, ["candidate_count"], getv(from_object, ["candidateCount"]))

    if getv(from_object, ["gcsUri"]) is not None:
        setv(to_object, ["gcs_uri"], getv(from_object, ["gcsUri"]))

    if getv(from_object, ["groundingConfig"]) is not None:
        setv(to_object, ["grounding_config"], getv(from_object, ["groundingConfig"]))

    if getv(from_object, ["hasPromptVariable"]) is not None:
        setv(
            to_object, ["has_prompt_variable"], getv(from_object, ["hasPromptVariable"])
        )

    if getv(from_object, ["logprobs"]) is not None:
        setv(to_object, ["logprobs"], getv(from_object, ["logprobs"]))

    if getv(from_object, ["maxOutputTokens"]) is not None:
        setv(to_object, ["max_output_tokens"], getv(from_object, ["maxOutputTokens"]))

    if getv(from_object, ["note"]) is not None:
        setv(to_object, ["note"], getv(from_object, ["note"]))

    if getv(from_object, ["promptApiSchema"]) is not None:
        setv(to_object, ["prompt_api_schema"], getv(from_object, ["promptApiSchema"]))

    if getv(from_object, ["promptType"]) is not None:
        setv(to_object, ["prompt_type"], getv(from_object, ["promptType"]))

    if getv(from_object, ["seedEnabled"]) is not None:
        setv(to_object, ["seed_enabled"], getv(from_object, ["seedEnabled"]))

    if getv(from_object, ["seedValue"]) is not None:
        setv(to_object, ["seed_value"], getv(from_object, ["seedValue"]))

    if getv(from_object, ["stopSequences"]) is not None:
        setv(to_object, ["stop_sequences"], getv(from_object, ["stopSequences"]))

    if getv(from_object, ["systemInstruction"]) is not None:
        setv(
            to_object, ["system_instruction"], getv(from_object, ["systemInstruction"])
        )

    if getv(from_object, ["systemInstructionGcsUri"]) is not None:
        setv(
            to_object,
            ["system_instruction_gcs_uri"],
            getv(from_object, ["systemInstructionGcsUri"]),
        )

    if getv(from_object, ["temperature"]) is not None:
        setv(to_object, ["temperature"], getv(from_object, ["temperature"]))

    if getv(from_object, ["text"]) is not None:
        setv(to_object, ["text"], getv(from_object, ["text"]))

    if getv(from_object, ["topK"]) is not None:
        setv(to_object, ["top_k"], getv(from_object, ["topK"]))

    if getv(from_object, ["topP"]) is not None:
        setv(to_object, ["top_p"], getv(from_object, ["topP"]))

    return to_object


def _Dataset_from_vertex(
    from_object: Union[dict[str, Any], object],
    parent_object: Optional[dict[str, Any]] = None,
) -> dict[str, Any]:
    to_object: dict[str, Any] = {}
    if getv(from_object, ["metadata"]) is not None:
        setv(
            to_object,
            ["metadata"],
            _SchemaTextPromptDatasetMetadata_from_vertex(
                getv(from_object, ["metadata"]), to_object
            ),
        )

    if getv(from_object, ["encryptionSpec"]) is not None:
        setv(to_object, ["encryption_spec"], getv(from_object, ["encryptionSpec"]))

    if getv(from_object, ["createTime"]) is not None:
        setv(to_object, ["create_time"], getv(from_object, ["createTime"]))

    if getv(from_object, ["dataItemCount"]) is not None:
        setv(to_object, ["data_item_count"], getv(from_object, ["dataItemCount"]))

    if getv(from_object, ["description"]) is not None:
        setv(to_object, ["description"], getv(from_object, ["description"]))

    if getv(from_object, ["displayName"]) is not None:
        setv(to_object, ["display_name"], getv(from_object, ["displayName"]))

    if getv(from_object, ["etag"]) is not None:
        setv(to_object, ["etag"], getv(from_object, ["etag"]))

    if getv(from_object, ["labels"]) is not None:
        setv(to_object, ["labels"], getv(from_object, ["labels"]))

    if getv(from_object, ["metadataArtifact"]) is not None:
        setv(to_object, ["metadata_artifact"], getv(from_object, ["metadataArtifact"]))

    if getv(from_object, ["metadataSchemaUri"]) is not None:
        setv(
            to_object, ["metadata_schema_uri"], getv(from_object, ["metadataSchemaUri"])
        )

    if getv(from_object, ["modelReference"]) is not None:
        setv(to_object, ["model_reference"], getv(from_object, ["modelReference"]))

    if getv(from_object, ["name"]) is not None:
        setv(to_object, ["name"], getv(from_object, ["name"]))

    if getv(from_object, ["satisfiesPzi"]) is not None:
        setv(to_object, ["satisfies_pzi"], getv(from_object, ["satisfiesPzi"]))

    if getv(from_object, ["satisfiesPzs"]) is not None:
        setv(to_object, ["satisfies_pzs"], getv(from_object, ["satisfiesPzs"]))

    if getv(from_object, ["savedQueries"]) is not None:
        setv(to_object, ["saved_queries"], getv(from_object, ["savedQueries"]))

    if getv(from_object, ["updateTime"]) is not None:
        setv(to_object, ["update_time"], getv(from_object, ["updateTime"]))

    return to_object


def _DatasetVersion_from_vertex(
    from_object: Union[dict[str, Any], object],
    parent_object: Optional[dict[str, Any]] = None,
) -> dict[str, Any]:
    to_object: dict[str, Any] = {}
    if getv(from_object, ["metadata"]) is not None:
        setv(
            to_object,
            ["metadata"],
            _SchemaTextPromptDatasetMetadata_from_vertex(
                getv(from_object, ["metadata"]), to_object
            ),
        )

    if getv(from_object, ["bigQueryDatasetName"]) is not None:
        setv(
            to_object,
            ["big_query_dataset_name"],
            getv(from_object, ["bigQueryDatasetName"]),
        )

    if getv(from_object, ["createTime"]) is not None:
        setv(to_object, ["create_time"], getv(from_object, ["createTime"]))

    if getv(from_object, ["displayName"]) is not None:
        setv(to_object, ["display_name"], getv(from_object, ["displayName"]))

    if getv(from_object, ["etag"]) is not None:
        setv(to_object, ["etag"], getv(from_object, ["etag"]))

    if getv(from_object, ["modelReference"]) is not None:
        setv(to_object, ["model_reference"], getv(from_object, ["modelReference"]))

    if getv(from_object, ["name"]) is not None:
        setv(to_object, ["name"], getv(from_object, ["name"]))

    if getv(from_object, ["satisfiesPzi"]) is not None:
        setv(to_object, ["satisfies_pzi"], getv(from_object, ["satisfiesPzi"]))

    if getv(from_object, ["satisfiesPzs"]) is not None:
        setv(to_object, ["satisfies_pzs"], getv(from_object, ["satisfiesPzs"]))

    if getv(from_object, ["updateTime"]) is not None:
        setv(to_object, ["update_time"], getv(from_object, ["updateTime"]))

    return to_object


class PromptManagement(_api_module.BaseModule):

    def _create_dataset_resource(
        self,
        *,
        config: Optional[types.CreateDatasetConfigOrDict] = None,
        name: Optional[str] = None,
        display_name: Optional[str] = None,
        metadata_schema_uri: Optional[str] = None,
        metadata: Optional[types.SchemaTextPromptDatasetMetadataOrDict] = None,
        description: Optional[str] = None,
        encryption_spec: Optional[genai_types.EncryptionSpecOrDict] = None,
        model_reference: Optional[str] = None,
    ) -> types.DatasetOperation:
        """
        Creates a dataset resource to store prompts.
        """

        parameter_model = types._CreateDatasetParameters(
            config=config,
            name=name,
            display_name=display_name,
            metadata_schema_uri=metadata_schema_uri,
            metadata=metadata,
            description=description,
            encryption_spec=encryption_spec,
            model_reference=model_reference,
        )

        request_url_dict: Optional[dict[str, str]]
        if not self._api_client.vertexai:
            raise ValueError("This method is only supported in the Vertex AI client.")
        else:
            request_dict = _CreateDatasetParameters_to_vertex(parameter_model)
            request_url_dict = request_dict.get("_url")
            if request_url_dict:
                path = "datasets".format_map(request_url_dict)
            else:
                path = "datasets"

        query_params = request_dict.get("_query")
        if query_params:
            path = f"{path}?{urlencode(query_params)}"
        # TODO: remove the hack that pops config.
        request_dict.pop("config", None)

        http_options: Optional[types.HttpOptions] = None
        if (
            parameter_model.config is not None
            and parameter_model.config.http_options is not None
        ):
            http_options = parameter_model.config.http_options

        request_dict = _common.convert_to_dict(request_dict)
        request_dict = _common.encode_unserializable_types(request_dict)

        response = self._api_client.request("post", path, request_dict, http_options)

        response_dict = "" if not response.body else json.loads(response.body)

        if self._api_client.vertexai:
            response_dict = _DatasetOperation_from_vertex(response_dict)

        return_value = types.DatasetOperation._from_response(
            response=response_dict, kwargs=parameter_model.model_dump()
        )

        self._api_client._verify_response(return_value)
        return return_value

    def _create_dataset_version_resource(
        self,
        *,
        config: Optional[types.CreateDatasetVersionConfigOrDict] = None,
        dataset_name: Optional[str] = None,
        dataset_version: Optional[types.DatasetVersionOrDict] = None,
        parent: Optional[str] = None,
        display_name: Optional[str] = None,
    ) -> types.DatasetOperation:
        """
        Creates a dataset version resource to store prompts.
        """

        parameter_model = types._CreateDatasetVersionParameters(
            config=config,
            dataset_name=dataset_name,
            dataset_version=dataset_version,
            parent=parent,
            display_name=display_name,
        )

        request_url_dict: Optional[dict[str, str]]
        if not self._api_client.vertexai:
            raise ValueError("This method is only supported in the Vertex AI client.")
        else:
            request_dict = _CreateDatasetVersionParameters_to_vertex(parameter_model)
            request_url_dict = request_dict.get("_url")
            if request_url_dict:
                path = "datasets/{name}/datasetVersions".format_map(request_url_dict)
            else:
                path = "datasets/{name}/datasetVersions"

        query_params = request_dict.get("_query")
        if query_params:
            path = f"{path}?{urlencode(query_params)}"
        # TODO: remove the hack that pops config.
        request_dict.pop("config", None)

        http_options: Optional[types.HttpOptions] = None
        if (
            parameter_model.config is not None
            and parameter_model.config.http_options is not None
        ):
            http_options = parameter_model.config.http_options

        request_dict = _common.convert_to_dict(request_dict)
        request_dict = _common.encode_unserializable_types(request_dict)

        response = self._api_client.request("post", path, request_dict, http_options)

        response_dict = "" if not response.body else json.loads(response.body)

        if self._api_client.vertexai:
            response_dict = _DatasetOperation_from_vertex(response_dict)

        return_value = types.DatasetOperation._from_response(
            response=response_dict, kwargs=parameter_model.model_dump()
        )

        self._api_client._verify_response(return_value)
        return return_value

    def _get_dataset_resource(
        self,
        *,
        config: Optional[types.VertexBaseConfigOrDict] = None,
        name: Optional[str] = None,
    ) -> types.Dataset:
        """
        Gets a dataset resource to store prompts.
        """

        parameter_model = types._GetDatasetParameters(
            config=config,
            name=name,
        )

        request_url_dict: Optional[dict[str, str]]
        if not self._api_client.vertexai:
            raise ValueError("This method is only supported in the Vertex AI client.")
        else:
            request_dict = _GetDatasetParameters_to_vertex(parameter_model)
            request_url_dict = request_dict.get("_url")
            if request_url_dict:
                path = "datasets/{name}".format_map(request_url_dict)
            else:
                path = "datasets/{name}"

        query_params = request_dict.get("_query")
        if query_params:
            path = f"{path}?{urlencode(query_params)}"
        # TODO: remove the hack that pops config.
        request_dict.pop("config", None)

        http_options: Optional[types.HttpOptions] = None
        if (
            parameter_model.config is not None
            and parameter_model.config.http_options is not None
        ):
            http_options = parameter_model.config.http_options

        request_dict = _common.convert_to_dict(request_dict)
        request_dict = _common.encode_unserializable_types(request_dict)

        response = self._api_client.request("get", path, request_dict, http_options)

        response_dict = "" if not response.body else json.loads(response.body)

        if self._api_client.vertexai:
            response_dict = _Dataset_from_vertex(response_dict)

        return_value = types.Dataset._from_response(
            response=response_dict, kwargs=parameter_model.model_dump()
        )

        self._api_client._verify_response(return_value)
        return return_value

    def _get_dataset_version_resource(
        self,
        *,
        config: Optional[types.VertexBaseConfigOrDict] = None,
        dataset_id: Optional[str] = None,
        dataset_version_id: Optional[str] = None,
    ) -> types.DatasetVersion:
        """
        Gets a dataset version resource to store prompts.
        """

        parameter_model = types._GetDatasetVersionParameters(
            config=config,
            dataset_id=dataset_id,
            dataset_version_id=dataset_version_id,
        )

        request_url_dict: Optional[dict[str, str]]
        if not self._api_client.vertexai:
            raise ValueError("This method is only supported in the Vertex AI client.")
        else:
            request_dict = _GetDatasetVersionParameters_to_vertex(parameter_model)
            request_url_dict = request_dict.get("_url")
            if request_url_dict:
                path = "datasets/{dataset_id}/datasetVersions/{dataset_version_id}".format_map(
                    request_url_dict
                )
            else:
                path = "datasets/{dataset_id}/datasetVersions/{dataset_version_id}"

        query_params = request_dict.get("_query")
        if query_params:
            path = f"{path}?{urlencode(query_params)}"
        # TODO: remove the hack that pops config.
        request_dict.pop("config", None)

        http_options: Optional[types.HttpOptions] = None
        if (
            parameter_model.config is not None
            and parameter_model.config.http_options is not None
        ):
            http_options = parameter_model.config.http_options

        request_dict = _common.convert_to_dict(request_dict)
        request_dict = _common.encode_unserializable_types(request_dict)

        response = self._api_client.request("get", path, request_dict, http_options)

        response_dict = "" if not response.body else json.loads(response.body)

        if self._api_client.vertexai:
            response_dict = _DatasetVersion_from_vertex(response_dict)

        return_value = types.DatasetVersion._from_response(
            response=response_dict, kwargs=parameter_model.model_dump()
        )

        self._api_client._verify_response(return_value)
        return return_value

    def _get_dataset_operation(
        self,
        *,
        config: Optional[types.GetDatasetOperationConfigOrDict] = None,
        dataset_id: Optional[str] = None,
        operation_id: Optional[str] = None,
    ) -> types.DatasetOperation:
        """
        Gets the operation from creating a dataset version.
        """

        parameter_model = types._GetDatasetOperationParameters(
            config=config,
            dataset_id=dataset_id,
            operation_id=operation_id,
        )

        request_url_dict: Optional[dict[str, str]]
        if not self._api_client.vertexai:
            raise ValueError("This method is only supported in the Vertex AI client.")
        else:
            request_dict = _GetDatasetOperationParameters_to_vertex(parameter_model)
            request_url_dict = request_dict.get("_url")
            if request_url_dict:
                path = "datasets/{dataset_id}/operations/{operation_id}".format_map(
                    request_url_dict
                )
            else:
                path = "datasets/{dataset_id}/operations/{operation_id}"

        query_params = request_dict.get("_query")
        if query_params:
            path = f"{path}?{urlencode(query_params)}"
        # TODO: remove the hack that pops config.
        request_dict.pop("config", None)

        http_options: Optional[types.HttpOptions] = None
        if (
            parameter_model.config is not None
            and parameter_model.config.http_options is not None
        ):
            http_options = parameter_model.config.http_options

        request_dict = _common.convert_to_dict(request_dict)
        request_dict = _common.encode_unserializable_types(request_dict)

        response = self._api_client.request("get", path, request_dict, http_options)

        response_dict = "" if not response.body else json.loads(response.body)

        if self._api_client.vertexai:
            response_dict = _DatasetOperation_from_vertex(response_dict)

        return_value = types.DatasetOperation._from_response(
            response=response_dict, kwargs=parameter_model.model_dump()
        )

        self._api_client._verify_response(return_value)
        return return_value

    def create_version(
        self,
        *,
        prompt: types.PromptOrDict,
        config: Optional[types.CreatePromptConfigOrDict] = None,
    ) -> types.Prompt:
        """Creates a new version of a prompt in a Vertex Dataset resource.

        If config.prompt_id is not provided, this method creates a new Dataset
        resource for the prompt and a new Dataset Version resource under that
        Dataset.
        If config.prompt_id is provided, this method creates a new Dataset
        Version resource under the existing Dataset resource with the provided
        prompt_id.

        When creating new Dataset and Dataset Version resources, this waits for
        the Dataset operations to complete before returning.

        Args:
          prompt: The prompt to create a version for.
          config: Optional configuration for creating the prompt version.

        Returns:
          A types.Prompt object representing the prompt with its associated
          Dataset and Dataset Version resources.
        """
        if isinstance(prompt, dict):
            prompt = types.Prompt(**prompt)
        if isinstance(config, dict):
            config = types.CreatePromptConfig(**config)
        elif not config:
            config = types.CreatePromptConfig()

        if config.encryption_spec and config.prompt_id:
            raise ValueError(
                "Encryption spec can only be used for creating new prompts, not for creating new prompt versions."
            )

        if not prompt.prompt_data:
            raise ValueError("Prompt data must be provided.")
        if not prompt.prompt_data.contents:
            raise ValueError("Prompt contents must be provided.")
        if not prompt.prompt_data.model:
            raise ValueError("Model name must be provided.")
        if (
            prompt.prompt_data
            and prompt.prompt_data.contents
            and len(prompt.prompt_data.contents) > 1
        ):
            raise ValueError("Multi-turn prompts are not currently supported.")

        prompt_metadata = _prompt_management_utils._create_dataset_metadata_from_prompt(
            prompt,
            variables=(
                prompt.prompt_data.variables
                if prompt.prompt_data and prompt.prompt_data.variables
                else None
            ),
        )

        if config and config.prompt_id:
            prompt_id = config.prompt_id
        else:
            prompt_id = None

        if config and config.version_display_name:
            version_name = config.version_display_name
        else:
            version_name = None

        dataset_id = prompt_id
        if (
            dataset_id
            and prompt._dataset
            and dataset_id != prompt._dataset.name.split("/")[-1]
        ):
            # prompt_id takes precedence over existing prompt resource if provided.
            logger.info(
                f"The provided prompt_id {prompt_id} is different from the"
                f" existing prompt resource {prompt._dataset.name} and will"
                " take precedence. Creating a new prompt version for prompt"
                f" with id: {prompt_id}."
            )
        if not dataset_id and prompt._dataset and prompt._dataset.name:
            dataset_id = prompt._dataset.name.split("/")[-1]

        # Step 1: Create the dataset resource for the prompt if it doesn't exist.
        if not dataset_id:
            create_prompt_dataset_operation = self._create_dataset_resource(
                display_name=(
                    config.prompt_display_name
                    if config and config.prompt_display_name
                    else f"prompt_{time.strftime('%Y%m%d-%H%M%S')}"
                ),
                name=f"projects/{self._api_client.project}/locations/{self._api_client.location}",
                metadata_schema_uri=_prompt_management_utils.PROMPT_SCHEMA_URI,
                metadata=prompt_metadata,
                model_reference=prompt.prompt_data.model,
                encryption_spec=(
                    config.encryption_spec
                    if config and config.encryption_spec
                    else None
                ),
            )
            dataset_resource_name = self._wait_for_operation(
                operation=create_prompt_dataset_operation,
                timeout=config.timeout if config else 90,
            )
            dataset_id = dataset_resource_name.split("/")[-1]

        # Step 2: Get the dataset resource
        dataset_resource = self._get_dataset_resource(
            name=dataset_id,
        )
        prompt._dataset = dataset_resource

        # Step 3: Create the dataset version
        create_dataset_version_operation = self._create_dataset_version_resource(
            dataset_name=dataset_id,
            display_name=(
                version_name
                if version_name
                else f"prompt_version_{time.strftime('%Y%m%d-%H%M%S')}"
            ),
        )
        dataset_version_resource_name = self._wait_for_operation(
            operation=create_dataset_version_operation,
            timeout=config.timeout if config else 90,
        )

        # Step 4: Get the dataset version resource and return it with the prompt
        dataset_version_resource = self._get_dataset_version_resource(
            dataset_id=dataset_id,
            dataset_version_id=dataset_version_resource_name.split("/")[-1],
        )
        prompt._dataset_version = dataset_version_resource
        return prompt

    def _wait_for_operation(
        self,
        operation: types.DatasetOperation,
        timeout: int,
    ) -> str:
        """Waits for a dataset operation to complete.

        Args:
          operation: The dataset operation to wait for.
          timeout: The maximum time to wait for the operation to complete.

        Returns:
          The name of the Dataset resource from the operation result.

        Raises:
          TimeoutError: If the operation does not complete within the timeout.
          ValueError: If the operation fails.
        """
        done = False
        prompt_dataset_operation: Optional[types.DatasetOperation] = None

        response_operation_name = operation.name
        dataset_id = response_operation_name.split("/datasets/")[1].split("/")[0]
        operation_id = response_operation_name.split("/")[-1]

        start_time = time.time()
        sleep_duration = 5
        wait_multiplier = 2
        max_wait_time = 60
        previous_time = time.time()

        while not done:
            if (time.time() - start_time) > timeout:
                raise TimeoutError(
                    "Create prompt operation did not complete within the"
                    f" specified timeout of {timeout} seconds."
                )
            current_time = time.time()
            if current_time - previous_time >= sleep_duration:
                sleep_duration = min(sleep_duration * wait_multiplier, max_wait_time)
                previous_time = current_time
            time.sleep(sleep_duration)
            prompt_dataset_operation = self._get_dataset_operation(
                dataset_id=dataset_id,
                operation_id=operation_id,
            )
            done = (
                prompt_dataset_operation.done
                if hasattr(prompt_dataset_operation, "done")
                else False
            )
        if (
            not prompt_dataset_operation
            or prompt_dataset_operation.response is None
            or prompt_dataset_operation.response.get("name") is None
        ):
            raise ValueError("Error creating prompt version resource.")
        if (
            hasattr(prompt_dataset_operation, "error")
            and prompt_dataset_operation.error is not None
        ):
            raise ValueError(
                f"Error creating prompt version resource: {prompt_dataset_operation.error}"
            )
        return prompt_dataset_operation.response.get("name")

    def get(
        self,
        *,
        prompt_id: str,
        config: Optional[types.GetPromptConfig] = None,
    ) -> types.Prompt:
        """Gets a prompt resource from a Vertex Dataset.

        Args:
          prompt_id: The id of the Vertex Dataset resource containing the prompt. For example, if the prompt resource name is "projects/123/locations/us-central1/datasets/456", then the prompt_id is "456".
          config: Optional configuration for getting the prompt.

        Returns:
            A types.Prompt object representing the prompt with its associated Dataset and Dataset Version resources.
        """

        prompt_dataset_resource = self._get_dataset_resource(name=prompt_id)
        prompt = _prompt_management_utils._create_prompt_from_dataset_metadata(
            prompt_dataset_resource,
        )
        prompt._dataset = prompt_dataset_resource

        if config and config.version_id:
            prompt_version_resource = self._get_dataset_version_resource(
                dataset_id=prompt_id,
                dataset_version_id=config.version_id,
            )
            prompt._dataset_version = prompt_version_resource

        return prompt


class AsyncPromptManagement(_api_module.BaseModule):

    async def _create_dataset_resource(
        self,
        *,
        config: Optional[types.CreateDatasetConfigOrDict] = None,
        name: Optional[str] = None,
        display_name: Optional[str] = None,
        metadata_schema_uri: Optional[str] = None,
        metadata: Optional[types.SchemaTextPromptDatasetMetadataOrDict] = None,
        description: Optional[str] = None,
        encryption_spec: Optional[genai_types.EncryptionSpecOrDict] = None,
        model_reference: Optional[str] = None,
    ) -> types.DatasetOperation:
        """
        Creates a dataset resource to store prompts.
        """

        parameter_model = types._CreateDatasetParameters(
            config=config,
            name=name,
            display_name=display_name,
            metadata_schema_uri=metadata_schema_uri,
            metadata=metadata,
            description=description,
            encryption_spec=encryption_spec,
            model_reference=model_reference,
        )

        request_url_dict: Optional[dict[str, str]]
        if not self._api_client.vertexai:
            raise ValueError("This method is only supported in the Vertex AI client.")
        else:
            request_dict = _CreateDatasetParameters_to_vertex(parameter_model)
            request_url_dict = request_dict.get("_url")
            if request_url_dict:
                path = "datasets".format_map(request_url_dict)
            else:
                path = "datasets"

        query_params = request_dict.get("_query")
        if query_params:
            path = f"{path}?{urlencode(query_params)}"
        # TODO: remove the hack that pops config.
        request_dict.pop("config", None)

        http_options: Optional[types.HttpOptions] = None
        if (
            parameter_model.config is not None
            and parameter_model.config.http_options is not None
        ):
            http_options = parameter_model.config.http_options

        request_dict = _common.convert_to_dict(request_dict)
        request_dict = _common.encode_unserializable_types(request_dict)

        response = await self._api_client.async_request(
            "post", path, request_dict, http_options
        )

        response_dict = "" if not response.body else json.loads(response.body)

        if self._api_client.vertexai:
            response_dict = _DatasetOperation_from_vertex(response_dict)

        return_value = types.DatasetOperation._from_response(
            response=response_dict, kwargs=parameter_model.model_dump()
        )

        self._api_client._verify_response(return_value)
        return return_value

    async def _create_dataset_version_resource(
        self,
        *,
        config: Optional[types.CreateDatasetVersionConfigOrDict] = None,
        dataset_name: Optional[str] = None,
        dataset_version: Optional[types.DatasetVersionOrDict] = None,
        parent: Optional[str] = None,
        display_name: Optional[str] = None,
    ) -> types.DatasetOperation:
        """
        Creates a dataset version resource to store prompts.
        """

        parameter_model = types._CreateDatasetVersionParameters(
            config=config,
            dataset_name=dataset_name,
            dataset_version=dataset_version,
            parent=parent,
            display_name=display_name,
        )

        request_url_dict: Optional[dict[str, str]]
        if not self._api_client.vertexai:
            raise ValueError("This method is only supported in the Vertex AI client.")
        else:
            request_dict = _CreateDatasetVersionParameters_to_vertex(parameter_model)
            request_url_dict = request_dict.get("_url")
            if request_url_dict:
                path = "datasets/{name}/datasetVersions".format_map(request_url_dict)
            else:
                path = "datasets/{name}/datasetVersions"

        query_params = request_dict.get("_query")
        if query_params:
            path = f"{path}?{urlencode(query_params)}"
        # TODO: remove the hack that pops config.
        request_dict.pop("config", None)

        http_options: Optional[types.HttpOptions] = None
        if (
            parameter_model.config is not None
            and parameter_model.config.http_options is not None
        ):
            http_options = parameter_model.config.http_options

        request_dict = _common.convert_to_dict(request_dict)
        request_dict = _common.encode_unserializable_types(request_dict)

        response = await self._api_client.async_request(
            "post", path, request_dict, http_options
        )

        response_dict = "" if not response.body else json.loads(response.body)

        if self._api_client.vertexai:
            response_dict = _DatasetOperation_from_vertex(response_dict)

        return_value = types.DatasetOperation._from_response(
            response=response_dict, kwargs=parameter_model.model_dump()
        )

        self._api_client._verify_response(return_value)
        return return_value

    async def _get_dataset_resource(
        self,
        *,
        config: Optional[types.VertexBaseConfigOrDict] = None,
        name: Optional[str] = None,
    ) -> types.Dataset:
        """
        Gets a dataset resource to store prompts.
        """

        parameter_model = types._GetDatasetParameters(
            config=config,
            name=name,
        )

        request_url_dict: Optional[dict[str, str]]
        if not self._api_client.vertexai:
            raise ValueError("This method is only supported in the Vertex AI client.")
        else:
            request_dict = _GetDatasetParameters_to_vertex(parameter_model)
            request_url_dict = request_dict.get("_url")
            if request_url_dict:
                path = "datasets/{name}".format_map(request_url_dict)
            else:
                path = "datasets/{name}"

        query_params = request_dict.get("_query")
        if query_params:
            path = f"{path}?{urlencode(query_params)}"
        # TODO: remove the hack that pops config.
        request_dict.pop("config", None)

        http_options: Optional[types.HttpOptions] = None
        if (
            parameter_model.config is not None
            and parameter_model.config.http_options is not None
        ):
            http_options = parameter_model.config.http_options

        request_dict = _common.convert_to_dict(request_dict)
        request_dict = _common.encode_unserializable_types(request_dict)

        response = await self._api_client.async_request(
            "get", path, request_dict, http_options
        )

        response_dict = "" if not response.body else json.loads(response.body)

        if self._api_client.vertexai:
            response_dict = _Dataset_from_vertex(response_dict)

        return_value = types.Dataset._from_response(
            response=response_dict, kwargs=parameter_model.model_dump()
        )

        self._api_client._verify_response(return_value)
        return return_value

    async def _get_dataset_version_resource(
        self,
        *,
        config: Optional[types.VertexBaseConfigOrDict] = None,
        dataset_id: Optional[str] = None,
        dataset_version_id: Optional[str] = None,
    ) -> types.DatasetVersion:
        """
        Gets a dataset version resource to store prompts.
        """

        parameter_model = types._GetDatasetVersionParameters(
            config=config,
            dataset_id=dataset_id,
            dataset_version_id=dataset_version_id,
        )

        request_url_dict: Optional[dict[str, str]]
        if not self._api_client.vertexai:
            raise ValueError("This method is only supported in the Vertex AI client.")
        else:
            request_dict = _GetDatasetVersionParameters_to_vertex(parameter_model)
            request_url_dict = request_dict.get("_url")
            if request_url_dict:
                path = "datasets/{dataset_id}/datasetVersions/{dataset_version_id}".format_map(
                    request_url_dict
                )
            else:
                path = "datasets/{dataset_id}/datasetVersions/{dataset_version_id}"

        query_params = request_dict.get("_query")
        if query_params:
            path = f"{path}?{urlencode(query_params)}"
        # TODO: remove the hack that pops config.
        request_dict.pop("config", None)

        http_options: Optional[types.HttpOptions] = None
        if (
            parameter_model.config is not None
            and parameter_model.config.http_options is not None
        ):
            http_options = parameter_model.config.http_options

        request_dict = _common.convert_to_dict(request_dict)
        request_dict = _common.encode_unserializable_types(request_dict)

        response = await self._api_client.async_request(
            "get", path, request_dict, http_options
        )

        response_dict = "" if not response.body else json.loads(response.body)

        if self._api_client.vertexai:
            response_dict = _DatasetVersion_from_vertex(response_dict)

        return_value = types.DatasetVersion._from_response(
            response=response_dict, kwargs=parameter_model.model_dump()
        )

        self._api_client._verify_response(return_value)
        return return_value

    async def _get_dataset_operation(
        self,
        *,
        config: Optional[types.GetDatasetOperationConfigOrDict] = None,
        dataset_id: Optional[str] = None,
        operation_id: Optional[str] = None,
    ) -> types.DatasetOperation:
        """
        Gets the operation from creating a dataset version.
        """

        parameter_model = types._GetDatasetOperationParameters(
            config=config,
            dataset_id=dataset_id,
            operation_id=operation_id,
        )

        request_url_dict: Optional[dict[str, str]]
        if not self._api_client.vertexai:
            raise ValueError("This method is only supported in the Vertex AI client.")
        else:
            request_dict = _GetDatasetOperationParameters_to_vertex(parameter_model)
            request_url_dict = request_dict.get("_url")
            if request_url_dict:
                path = "datasets/{dataset_id}/operations/{operation_id}".format_map(
                    request_url_dict
                )
            else:
                path = "datasets/{dataset_id}/operations/{operation_id}"

        query_params = request_dict.get("_query")
        if query_params:
            path = f"{path}?{urlencode(query_params)}"
        # TODO: remove the hack that pops config.
        request_dict.pop("config", None)

        http_options: Optional[types.HttpOptions] = None
        if (
            parameter_model.config is not None
            and parameter_model.config.http_options is not None
        ):
            http_options = parameter_model.config.http_options

        request_dict = _common.convert_to_dict(request_dict)
        request_dict = _common.encode_unserializable_types(request_dict)

        response = await self._api_client.async_request(
            "get", path, request_dict, http_options
        )

        response_dict = "" if not response.body else json.loads(response.body)

        if self._api_client.vertexai:
            response_dict = _DatasetOperation_from_vertex(response_dict)

        return_value = types.DatasetOperation._from_response(
            response=response_dict, kwargs=parameter_model.model_dump()
        )

        self._api_client._verify_response(return_value)
        return return_value
