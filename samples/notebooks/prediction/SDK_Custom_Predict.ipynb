{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://github.com/googleapis/python-aiplatform/blob/main/samples/notebooks/prediction/SDK_Custom_Predict.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO",
        "tags": []
      },
      "source": [
        "## Overview\n",
        "\n",
        "This tutorial walks through building a custom container using the Custom Prediction Routine model server to serve a scikit-learn model on Vertex Predictions. This is currently an **experimental** feature and not yet officially supported by the Vertex AI SDK. In this tutorial, we'll be installing the Vertex AI SDK from an experimental branch on github. \n",
        "\n",
        "\n",
        "\n",
        "### Dataset\n",
        "\n",
        "This tutorial uses R.A. Fisher's Iris dataset, a small dataset that is popular for trying out machine learning techniques. Each instance has four numerical features, which are different measurements of a flower, and a target label that\n",
        "marks it as one of three types of iris: Iris setosa, Iris versicolour, or Iris virginica.\n",
        "\n",
        "This tutorial uses [the copy of the Iris dataset included in the\n",
        "scikit-learn library](https://scikit-learn.org/stable/datasets/index.html#iris-dataset).\n",
        "\n",
        "### Objective\n",
        "\n",
        "The goal is to:\n",
        "- Train a model that uses a flower's measurements as input to predict what type of iris it is.\n",
        "- Save the model and its serialized pre-processor\n",
        "- Build a custom sklearn serving container with custom preprocessing using the Custom Prediction Routine model server\n",
        "- Upload and deploy custom container to Vertex Prediction\n",
        "\n",
        "This tutorial focuses more on deploying this model with Vertex AI than on\n",
        "the design of the model itself.\n",
        "\n",
        "### Costs \n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "\n",
        "Learn about [Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing), and use the [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze4-nDLfK4pw"
      },
      "source": [
        "### Set up your local development environment\n",
        "\n",
        "**If you are using Google Cloud Notebooks**, your environment already meets\n",
        "all the requirements to run this notebook. You can skip this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCuSR8GkAgzl"
      },
      "source": [
        "**Otherwise**, make sure your environment meets this notebook's requirements.\n",
        "You need the following:\n",
        "\n",
        "* Docker\n",
        "* Git\n",
        "* Google Cloud SDK (gcloud)\n",
        "* Python 3\n",
        "* virtualenv\n",
        "* Jupyter notebook running in a virtual environment with Python 3\n",
        "\n",
        "The Google Cloud guide to [Setting up a Python development\n",
        "environment](https://cloud.google.com/python/setup) and the [Jupyter\n",
        "installation guide](https://jupyter.org/install) provide detailed instructions\n",
        "for meeting these requirements. The following steps provide a condensed set of\n",
        "instructions:\n",
        "\n",
        "1. [Install and initialize the Cloud SDK.](https://cloud.google.com/sdk/docs/)\n",
        "\n",
        "1. [Install Python 3.](https://cloud.google.com/python/setup#installing_python)\n",
        "\n",
        "1. [Install\n",
        "   virtualenv](https://cloud.google.com/python/setup#installing_and_using_virtualenv)\n",
        "   and create a virtual environment that uses Python 3. Activate the virtual environment.\n",
        "\n",
        "1. To install Jupyter, run `pip install jupyter` on the\n",
        "command-line in a terminal shell.\n",
        "\n",
        "1. To launch Jupyter, run `jupyter notebook` on the command-line in a terminal shell.\n",
        "\n",
        "1. Open this notebook in the Jupyter Notebook Dashboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "### Install additional packages\n",
        "\n",
        "Install additional package dependencies not installed in your notebook environment, such as NumPy, Scikit-learn, FastAPI, Uvicorn, and joblib. Use the latest major GA version of each package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "747f59abb3a5"
      },
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "fastapi\n",
        "uvicorn\n",
        "joblib~=1.0\n",
        "numpy~=1.20\n",
        "scikit-learn~=0.24\n",
        "google-cloud-storage>=1.26.0,<2.0.0dev\n",
        "google-cloud-aiplatform[prediction] @ git+https://github.com/googleapis/python-aiplatform.git@custom-prediction-routine"
      ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**The model you deploy will have a different set of dependencies pre-installed than your notebook environment has. You should not assume that because things work in the notebook, they will work in the model. Instead, we will be very explicit about the dependencies for the model by listing them in requirements.txt and then use `pip install` to install the exact same dependencies in the notebook. Please note, of course, that there is a chance that we miss a dependency in requirements.txt that already exists in the notebook. If that's the case, things will run in the notebook, but not in the model. To guard against that, we will test the model locally before deploying to the cloud.**"
     ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyy5Lbnzg5fi"
      },
      "outputs": [],
      "source": [
        "# Install the same dependencies used in the serving container in the notebook\n",
        "# environment.\n",
        "%pip install -U --user -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhq5zEbGg0XX"
      },
      "source": [
        "### Restart the kernel\n",
        "\n",
        "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzrelQZ22IZj"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWEdiXsJg0XY"
      },
      "source": [
        "## Before you begin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
        "\n",
        "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "1. [Enable the Vertex AI API and Compute Engine API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,compute_component).\n",
        "\n",
        "1. If you are running this notebook locally, you will need to install the [Cloud SDK](https://cloud.google.com/sdk).\n",
        "\n",
        "1. Enter your project ID in the cell below. Then run the cell to make sure the\n",
        "Cloud SDK uses the right project for all the commands in this notebook.\n",
        "\n",
        "**Note**: Jupyter runs lines prefixed with `!` or `%` as shell commands, and it interpolates Python variables with `$` or `{}` into these commands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [],
      "source": [
        "# Get your Google Cloud project ID from gcloud\n",
        "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "\n",
        "try:\n",
        "    PROJECT_ID = shell_output[0]\n",
        "except IndexError:\n",
        "    PROJECT_ID = None\n",
        "\n",
        "print(\"Project ID:\", PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJYoRfYng0XZ"
      },
      "source": [
        "Otherwise, set your project ID here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riG_qUokg0XZ"
      },
      "outputs": [],
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
        "    PROJECT_ID = \"[PROJ_ID]\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEqT2Y4DJmf"
      },
      "source": [
        "### Configure project and resource names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "MODEL_ARTIFACT_DIR = \"sklearn-cpr-model\"  # @param {type:\"string\"}\n",
        "REPOSITORY = \"custom-container-prediction\"  # @param {type:\"string\"}\n",
        "IMAGE = \"sklearn-cpr-server\"  # @param {type:\"string\"}\n",
        "MODEL_DISPLAY_NAME = \"sklearn-cpr-model\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca1a915d641d"
      },
      "source": [
        "`REGION` - Used for operations\n",
        "throughout the rest of this notebook. Make sure to [choose a region where Cloud\n",
        "Vertex AI services are\n",
        "available](https://cloud.google.com/vertex-ai/docs/general/locations#feature-availability). You may\n",
        "not use a Multi-Regional Storage bucket for prediction with Vertex AI.\n",
        "\n",
        "`MODEL_ARTIFACT_DIR` - Folder directory path to your model artifacts within a Cloud Storage bucket, for example: \"my-models/fraud-detection/trial-4\"\n",
        "\n",
        "`REPOSITORY` - Name of the Artifact Repository to create or use.\n",
        "\n",
        "`IMAGE` - Name of the container image that will be pushed.\n",
        "\n",
        "`MODEL_DISPLAY_NAME` - Display name of Vertex AI Model resource."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62f861b68b50"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "To update your model artifacts without re-building the container, you must upload your model\n",
        "artifacts and any custom code to Cloud Storage.\n",
        "\n",
        "Set the name of your Cloud Storage bucket below. It must be unique across all\n",
        "Cloud Storage buckets and start with `gs://`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9724b00aeead"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"gs://[BUCKET_NAME]\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58cb4f5895f0"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d2208676cee"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION $BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c664a5abc11a"
      },
      "source": [
        "Finally, validate access to your Cloud Storage bucket by examining its contents (nothing will be outputted for new buckets):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c1b1c29f5f6"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al $BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c2d091d9e73"
      },
      "source": [
        "## Write your pre-processor\n",
        "Scaling training data so each numerical feature column has a mean of 0 and a standard deviation of 1 [can improve your model](https://developers.google.com/machine-learning/crash-course/representation/cleaning-data).\n",
        "\n",
        "Create `preprocess.py`, which contains a class to do this scaling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e74556ea0b4"
      },
      "outputs": [],
      "source": [
        "%mkdir src_dir\n",
        "%mkdir model_artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58d843d21fa8"
      },
      "outputs": [],
      "source": [
        "%%writefile src_dir/preprocess.py\n",
        "import numpy as np\n",
        "\n",
        "class MySimpleScaler(object):\n",
        "    def __init__(self):\n",
        "        self._means = None\n",
        "        self._stds = None\n",
        "\n",
        "    def preprocess(self, data):\n",
        "        if self._means is None:  # during training only\n",
        "            self._means = np.mean(data, axis=0)\n",
        "\n",
        "        if self._stds is None:  # during training only\n",
        "            self._stds = np.std(data, axis=0)\n",
        "            if not self._stds.all():\n",
        "                raise ValueError(\"At least one column has standard deviation of 0.\")\n",
        "\n",
        "        return (data - self._means) / self._stds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b816cd52f4b"
      },
      "source": [
        "## Train and store model with pre-processor\n",
        "Next, use `preprocess.MySimpleScaler` to preprocess the iris data, then train a model using scikit-learn.\n",
        "\n",
        "At the end, export your trained model as a joblib (`.joblib`) file and export your `MySimpleScaler` instance as a pickle (`.pkl`) file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43e47249f736"
      },
      "outputs": [],
      "source": [
        "%cd src_dir/\n",
        "\n",
        "import pickle\n",
        "\n",
        "import joblib\n",
        "from preprocess import MySimpleScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "scaler = MySimpleScaler()\n",
        "\n",
        "X = scaler.preprocess(iris.data)\n",
        "y = iris.target\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "joblib.dump(model, \"../model_artifacts/model.joblib\")\n",
        "with open(\"../model_artifacts/preprocessor.pkl\", \"wb\") as f:\n",
        "    pickle.dump(scaler, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3849066a33bd"
      },
      "source": [
        "### Upload model artifacts and custom code to Cloud Storage\n",
        "\n",
        "Before you can deploy your model for serving, Vertex AI needs access to the following files in Cloud Storage:\n",
        "\n",
        "* `model.joblib` (model artifact)\n",
        "* `preprocessor.pkl` (model artifact)\n",
        "\n",
        "Run the following commands to upload your files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca67ee52d4d9"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "!gsutil cp model_artifacts/* {BUCKET_NAME}/{MODEL_ARTIFACT_DIR}/\n",
        "!gsutil ls {BUCKET_NAME}/{MODEL_ARTIFACT_DIR}/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "480a1d88ecdb"
      },
      "source": [
        "## Build a custom serving container using the CPR model server\n",
        "\n",
        "Now that the model and processor has been trained and saved, it's time to build the custom serving container. Typically building a serving container requires writing model server code. However, with the Custom Prediction Routine feature, Vertex AI Prediction has published a [model server](https://github.com/googleapis/python-aiplatform/blob/custom-prediction-routine/google/cloud/aiplatform/prediction/model_server.py) that can be used out of the box.\n",
        "\n",
        "A custom serving container contains the follow 3 pieces of code:\n",
        "1. [Model server](https://github.com/googleapis/python-aiplatform/blob/custom-prediction-routine/google/cloud/aiplatform/prediction/model_server.py)\n",
        "    * HTTP server that hosts the model\n",
        "    * Responsible for setting up routes/ports/etc.\n",
        "    * In this example we will use the `google.cloud.aiplatform.prediction.model_server.ModelServer` out of the box.\n",
        "1. [Request Handler](https://github.com/googleapis/python-aiplatform/blob/custom-prediction-routine/google/cloud/aiplatform/prediction/handler.py)\n",
        "    * Responsible for webserver aspects of handling a request, such as deserializing the request body, and serializing the reponse, setting response headers, etc.\n",
        "    * In this example, we will use the default Handler, `google.cloud.aiplatform.prediction.handler.PredictionHandler` provided in the SDK.\n",
        "1. [Predictor](https://github.com/googleapis/python-aiplatform/blob/custom-prediction-routine/google/cloud/aiplatform/prediction/predictor.py)\n",
        "    * Responsible for the ML logic for processing a prediction request.\n",
        "\n",
        "Each of these three pieces can be customized based on the requirements of the custom container. In this example, we will only be implementing the `Predictor`.\n",
        "\n",
        "\n",
        "A [`Predictor`](https://github.com/googleapis/python-aiplatform/blob/custom-prediction-routine/google/cloud/aiplatform/prediction/predictor.py) must implement the following interface:\n",
        "\n",
        "```\n",
        "class Predictor:\n",
        "    \"\"\"Interface for Predictor class that users would be implementing.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        raise NotImplementedError(\"Predictor.__init__ has not been implemented yet.\")\n",
        "\n",
        "    def load(self, gcs_artifacts_uri: str):\n",
        "        \"\"\"Loads the model artifact.\n",
        "        Args:\n",
        "            gcs_artifacts_uri (str):\n",
        "                Required. The value of the environment variable AIP_STORAGE_URI.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Predictor.load has not been implemented yet.\")\n",
        "\n",
        "    def preprocess(self, prediction_input: Any) -> Any:\n",
        "        \"\"\"Preprocesses the prediction input before doing the prediction.\n",
        "        Args:\n",
        "            prediction_input (Any):\n",
        "                Required. The prediction input needs to be preprocessed.\n",
        "        Returns:\n",
        "            The preprocessed prediction input.\n",
        "        \"\"\"\n",
        "        return prediction_input\n",
        "\n",
        "    def predict(self, instances: Any) -> Any:\n",
        "        \"\"\"Performs prediction.\n",
        "        Args:\n",
        "            instances (Any):\n",
        "                Required. The instances to perform prediction.\n",
        "        Returns:\n",
        "            Prediction results.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Predictor.predict has not been implemented yet.\")\n",
        "\n",
        "    def postprocess(self, prediction_results: Any) -> Any:\n",
        "        \"\"\"Postprocesses the prediction results.\n",
        "        Args:\n",
        "            prediction_results (Any):\n",
        "                Required. The prediction results.\n",
        "        Returns:\n",
        "            The postprocessed prediction results.\n",
        "        \"\"\"\n",
        "        return prediction_results\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KODNAqK5k8R"
      },
      "source": [
        "First, implement a custom `Predictor` that loads in both the preprocesor and the model. The preprocessor and the model will then be used at `predict` time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkh8DT7CCgQO"
      },
      "outputs": [],
      "source": [
        "%%writefile src_dir/predictor.py\n",
        "\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from google.cloud import storage\n",
        "from google.cloud.aiplatform.prediction.predictor import Predictor\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "\n",
        "class CprPredictor(Predictor):\n",
        "    \n",
        "    def __init__(self):\n",
        "        return\n",
        "    \n",
        "    def load(self, gcs_artifacts_uri: str):\n",
        "        \"\"\"Loads the preprocessor and model artifacts.\"\"\"\n",
        "        gcs_client = storage.Client()\n",
        "        with open(\"preprocessor.pkl\", 'wb') as preprocessor_f, open(\"model.joblib\", 'wb') as model_f:\n",
        "            gcs_client.download_blob_to_file(\n",
        "                f\"{gcs_artifacts_uri}/preprocessor.pkl\", preprocessor_f\n",
        "            )\n",
        "            gcs_client.download_blob_to_file(\n",
        "                f\"{gcs_artifacts_uri}/model.joblib\", model_f\n",
        "            )\n",
        "\n",
        "        with open(\"preprocessor.pkl\", \"rb\") as f:\n",
        "            preprocessor = pickle.load(f)\n",
        "\n",
        "        self._class_names = load_iris().target_names\n",
        "        self._model = joblib.load(\"model.joblib\")\n",
        "        self._preprocessor = preprocessor\n",
        "\n",
        "    def predict(self, instances):\n",
        "        \"\"\"Performs prediction.\"\"\"\n",
        "        instances = instances[\"instances\"]\n",
        "        inputs = np.asarray(instances)\n",
        "        preprocessed_inputs = self._preprocessor.preprocess(inputs)\n",
        "        outputs = self._model.predict(preprocessed_inputs)\n",
        "\n",
        "        return {\"predictions\": [self._class_names[class_num] for class_num in outputs]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waA_Jl5Q6E0W"
      },
      "source": [
        "Next, write the container's entrypoint file that will launch the `ModelServer` with the custom `CprPredictor`. Again, note that the default `PredictionHandler` is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mJbjxFCNueN"
      },
      "outputs": [],
      "source": [
        "%%writefile src_dir/entrypoint.py\n",
        "\n",
        "import os\n",
        "from typing import Optional, Type\n",
        "\n",
        "from google.cloud.aiplatform import prediction\n",
        "\n",
        "from predictor import CprPredictor\n",
        "\n",
        "\n",
        "def main(\n",
        "    predictor_class: Optional[Type[prediction.predictor.Predictor]] = None,\n",
        "    handler_class: Type[prediction.handler.Handler] = prediction.handler.PredictionHandler,\n",
        "    model_server_class: Type[prediction.model_server.ModelServer] = prediction.model_server.ModelServer,\n",
        "):\n",
        "    handler = handler_class(\n",
        "        os.environ.get(\"AIP_STORAGE_URI\"), predictor=predictor_class\n",
        "    )\n",
        "\n",
        "    return model_server_class(handler).start()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(\n",
        "        predictor_class=CprPredictor,\n",
        "        handler_class=prediction.handler.PredictionHandler\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51e149fdec1b"
      },
      "source": [
        "## Build and push container to Artifact Registry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bdb9a7768a5"
      },
      "source": [
        "### Build your container"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8phJWBhe7u9u"
      },
      "source": [
        "#### Set up credentials (Optional)\n",
        "\n",
        "Setting up credentials is only required to run the custom serving container locally.\n",
        "\n",
        "First enable the IAM API if it's not already enabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mERTlLb6dluB"
      },
      "outputs": [],
      "source": [
        "!gcloud services enable iam.googleapis.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "Follow these steps:\n",
        "\n",
        "1. In the Cloud Console, go to the [**Create service account key**\n",
        "   page](https://console.cloud.google.com/apis/credentials/serviceaccountkey).\n",
        "\n",
        "2. Click **Create service account**.\n",
        "\n",
        "3. In the **Service account name** field, enter a name, and\n",
        "   click **Create**.\n",
        "\n",
        "4. In the **Grant this service account access to project** section, click the **Role** drop-down list. Type \"Vertex AI\"\n",
        "into the filter box, and select\n",
        "   **Vertex AI Administrator**. Type \"Storage Object Admin\" into the filter box, and select **Storage Object Admin**.\n",
        "\n",
        "Next, generate the service account key, and save it to the `credentials.json` path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4lduXfvdluB"
      },
      "outputs": [],
      "source": [
        "SERVICE_ACCOUNT = \"[SERVICE_ACCCOUNT]\"  # @param {type:\"string\"}\n",
        "\n",
        "!gcloud iam service-accounts keys create credentials.json --iam-account=$SERVICE_ACCOUNT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "240578ec9efe"
      },
      "source": [
        "#### Write the Dockerfile\n",
        "\n",
        "Using `python:3.7` as a base image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d3a6b9ed22b"
      },
      "outputs": [],
      "source": [
        "%%writefile Dockerfile\n",
        "\n",
        "# Users select base images.\n",
        "FROM python:3.7\n",
        "\n",
        "# Sets the directories' permissions so that any user can access the folder.\n",
        "RUN mkdir -m 777 -p /home /usr/app\n",
        "ENV HOME=/home\n",
        "WORKDIR /usr/app\n",
        "\n",
        "# Only required for local runs\n",
        "COPY credentials.json credentials.json\n",
        "\n",
        "# Copies all the stuff to the image.\n",
        "COPY src_dir /usr/app/src_dir\n",
        "COPY requirements.txt /usr/app/requirements.txt\n",
        "\n",
        "# Installs python dependencies.\n",
        "RUN pip3 install --no-cache-dir -r /usr/app/requirements.txt\n",
        "\n",
        "# Informs Docker that the container listens on the specified ports at runtime.\n",
        "EXPOSE 8080\n",
        "\n",
        "# Sets up an entrypoint to start the model server.\n",
        "ENTRYPOINT [\"python3\", \"/usr/app/src_dir/entrypoint.py\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04c988201499"
      },
      "source": [
        "Build the image and tag the Artifact Registry path that you will push to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1e7d639b9cc"
      },
      "outputs": [],
      "source": [
        "!docker build \\\n",
        "    --tag={REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE} \\\n",
        "    ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b62ddf1def3"
      },
      "source": [
        "### Store test instances\n",
        "To learn more about formatting input instances in JSON, [read the documentation.](https://cloud.google.com/vertex-ai/docs/predictions/online-predictions-custom-models#request-body-details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6605e9e6186"
      },
      "outputs": [],
      "source": [
        "%%writefile instances.json\n",
        "{\n",
        "    \"instances\": [\n",
        "        [6.7, 3.1, 4.7, 1.5],\n",
        "        [4.6, 3.1, 1.5, 0.2]\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "147a555f6c93"
      },
      "source": [
        "### Run and test the container locally (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJe8TCr4ec4F"
      },
      "source": [
        "Run the container locally in detached mode and provide the environment variables that the container requires. These env vars will be provided to the container by Vertex Prediction once deployed. Test the `/health` and `/predict` routes, then stop the running image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62ed2d334d0f"
      },
      "outputs": [],
      "source": [
        "!docker run -d -p 80:8080 \\\n",
        "    --name=local-iris \\\n",
        "    -e AIP_HTTP_PORT=8080 \\\n",
        "    -e AIP_HEALTH_ROUTE=/health \\\n",
        "    -e AIP_PREDICT_ROUTE=/predict \\\n",
        "    -e AIP_STORAGE_URI={BUCKET_NAME}/{MODEL_ARTIFACT_DIR} \\\n",
        "    -e GOOGLE_APPLICATION_CREDENTIALS=credentials.json \\\n",
        "    {REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce629eea32fd"
      },
      "outputs": [],
      "source": [
        "!curl localhost/health"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56986f93438e"
      },
      "outputs": [],
      "source": [
        "!curl -X POST \\\n",
        "  -d @instances.json \\\n",
        "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
        "  localhost/predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a29fcbbe0188"
      },
      "outputs": [],
      "source": [
        "!docker stop local-iris"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "212b2935ea12"
      },
      "source": [
        "### Push the container to artifact registry\n",
        "\n",
        "Configure Docker to access Artifact Registry. Then push your container image to your Artifact Registry repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSFXCj3LdluJ"
      },
      "outputs": [],
      "source": [
        "!gcloud services list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABE9UpwSdluK"
      },
      "source": [
        "If `artifactregistry.googleapis.com` is not enabled in your project, enable the API before proceeding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDhLoQMydluK"
      },
      "outputs": [],
      "source": [
        "!gcloud services enable artifactregistry.googleapis.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09ffe2434e3d"
      },
      "outputs": [],
      "source": [
        "!gcloud beta artifacts repositories create {REPOSITORY} \\\n",
        "    --repository-format=docker \\\n",
        "    --location=$REGION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "293437024749"
      },
      "outputs": [],
      "source": [
        "!gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dd7448f4703"
      },
      "outputs": [],
      "source": [
        "!docker push {REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b438bfa2129f"
      },
      "source": [
        "## Deploy to Vertex AI\n",
        "\n",
        "Use the Python SDK to upload and deploy your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ae19df6a33e"
      },
      "source": [
        "### Upload the custom container model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d682d8388ec"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "574fb82d3eed"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2738154345d5"
      },
      "outputs": [],
      "source": [
        "model = aiplatform.Model.upload(\n",
        "    display_name=MODEL_DISPLAY_NAME,\n",
        "    artifact_uri=f\"{BUCKET_NAME}/{MODEL_ARTIFACT_DIR}\",\n",
        "    serving_container_image_uri=f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd1b85afc7df"
      },
      "source": [
        "### Deploy the model on Vertex AI\n",
        "After this step completes, the model is deployed and ready for online prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62cf66498a28"
      },
      "outputs": [],
      "source": [
        "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6883e7b07143"
      },
      "source": [
        "## Send predictions\n",
        "\n",
        "### Using Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d69ed411c2d3"
      },
      "outputs": [],
      "source": [
        "endpoint.predict(instances=[[6.7, 3.1, 4.7, 1.5], [4.6, 3.1, 1.5, 0.2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "370d22f53427"
      },
      "source": [
        "### Using REST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba55bc560d58"
      },
      "outputs": [],
      "source": [
        "ENDPOINT_ID = endpoint.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95c562b4e98b"
      },
      "outputs": [],
      "source": [
        "! curl \\\n",
        "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-d @instances.json \\\n",
        "https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}:predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa71174a7dd0"
      },
      "source": [
        "### Using gcloud CLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23b8e807b02c"
      },
      "outputs": [],
      "source": [
        "!gcloud ai endpoints predict $ENDPOINT_ID \\\n",
        "  --region=$REGION \\\n",
        "  --json-request=instances.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [],
      "source": [
        "# Undeploy model and delete endpoint\n",
        "endpoint.delete(force=True)\n",
        "\n",
        "# Delete the model resource\n",
        "model.delete()\n",
        "\n",
        "# Delete the container image from Artifact Registry\n",
        "!gcloud artifacts docker images delete \\\n",
        "    --quiet \\\n",
        "    --delete-tags \\\n",
        "    {REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SDK_Custom_Predict.ipynb",
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m89",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m89"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
